<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Shel Kong" />


<title>CH03 Data Pre-processing</title>

<script src="libs/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="libs/bootstrap-2.3.2/css/cosmo.min.css" rel="stylesheet" />
<link href="libs/bootstrap-2.3.2/css/bootstrap-responsive.min.css" rel="stylesheet" />
<script src="libs/bootstrap-2.3.2/js/bootstrap.min.js"></script>

<style type="text/css">

/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
@media (max-width: 979px) {
  body {
    padding-top: 0;
  }
}

/* offset scroll position for anchor links (for fixed navbar)  */
@media (min-width: 980px) {
  .section h2 {
    padding-top: 52px;
    margin-top: -52px;
  }
  .section h3 {
    padding-top: 52px;
    margin-top: -52px;
  }
}


/* don't use link color in navbar */
.dropdown-menu>li>a {
  color: black;
}

/* some padding for disqus */
#disqus_thread {
  margin-top: 45px;
}

</style>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="libs/highlight/default.css"
      type="text/css" />
<script src="libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>


<link rel="stylesheet" href="include/custom.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="container-fluid main-container">


<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-inner">
    <div class="container">
      <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="brand" href="/notes/">Shel's Notes</a>
      <div class="nav-collapse collapse">
        <ul class="nav">
          <!-- <li><a href="/notes/">Home</a></li> -->
          <li><a href="http://kongscn.github.io/">My Blog</a></li>
          <!-- <li><a href='https://github.com/kongscn/notes'>Source of Notes</a></li> -->
          <li><a href='https://github.com/kongscn/notes/tree/gh-pages'>Source of Site</a></li>
          <li><a href='/notes/README.html'>About</a></li>
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </div>
</div>

<div id="header">
<h1 class="title">CH03 Data Pre-processing</h1>
<h4 class="author"><em>Shel Kong</em></h4>
<h4 class="date"><em>Sunday, August 17, 2014</em></h4>
</div>

<div id="TOC">
<ul>
<li><a href="#data-transformations-for-individual-predictors"><span class="toc-section-number">1</span> Data Transformations for Individual Predictors</a><ul>
<li><a href="#centering-and-scaling"><span class="toc-section-number">1.1</span> Centering and Scaling</a></li>
<li><a href="#transformations-to-resolve-skewness"><span class="toc-section-number">1.2</span> Transformations to Resolve Skewness</a></li>
</ul></li>
<li><a href="#data-transormations-for-multiple-predictors"><span class="toc-section-number">2</span> Data Transormations for Multiple Predictors</a><ul>
<li><a href="#transformations-to-resolve-outliers"><span class="toc-section-number">2.1</span> Transformations to Resolve Outliers</a></li>
<li><a href="#data-reduction-and-feature-extraction"><span class="toc-section-number">2.2</span> Data Reduction and Feature Extraction</a></li>
</ul></li>
<li><a href="#dealing-with-missing-values"><span class="toc-section-number">3</span> Dealing with Missing Values</a></li>
<li><a href="#removing-predictors"><span class="toc-section-number">4</span> Removing Predictors</a><ul>
<li><a href="#zero-variance-predictors"><span class="toc-section-number">4.1</span> Zero Variance Predictors</a></li>
<li><a href="#betwee-predictor-correlations"><span class="toc-section-number">4.2</span> Betwee-Predictor Correlations</a></li>
</ul></li>
<li><a href="#adding-predictors"><span class="toc-section-number">5</span> Adding Predictors</a></li>
<li><a href="#binning-predictors"><span class="toc-section-number">6</span> Binning Predictors</a></li>
</ul>
</div>

<pre class="r"><code>library(AppliedPredictiveModeling)
data(segmentationOriginal)</code></pre>
<p>Basic selection methods and tips. Check <a href="http://www.statmethods.net/management/subset.html">here</a> for a general introduction.</p>
<pre class="r"><code>segData = subset(segmentationOriginal, Case==&quot;Train&quot;)
cellID = segData$Cell
case = segData$Case
class = segData$Class
# Remove the  columns, 
# this can also be done by
# segData = segData[, -(1:3)]
# which is prefered in programming
segData = subset(segData, select=-(Cell:Class))

statusColNum = grep(&quot;Status&quot;, names(segData))
segData = segData[, -statusColNum]</code></pre>
<div id="data-transformations-for-individual-predictors" class="section level1">
<h1><span class="header-section-number">1</span> Data Transformations for Individual Predictors</h1>
<p>Data preparation can make or break a model’s predictive ability. How the predictors enter the mdel is important.</p>
<div id="centering-and-scaling" class="section level2">
<h2><span class="header-section-number">1.1</span> Centering and Scaling</h2>
<p>Most liner models benefit from standardizing predictors. The only real downside is a loss of interpretability of the individual values since the data are no longer in the original units.</p>
</div>
<div id="transformations-to-resolve-skewness" class="section level2">
<h2><span class="header-section-number">1.2</span> Transformations to Resolve Skewness</h2>
<p><span class="math">\[ \text{skewness} = \frac{\sum (x_i - \bar{x})^3}{(n-1) v^{3/2}} \]</span> where <span class="math">\[ v = \frac{\sum (x_i - \bar{x})^2}{n-1} \]</span></p>
<p>Box-Cox Transormations(Box and Cox, 1964) can be used to resolve skewness:</p>
<p><span class="math">\[
x^* = \left\{
  \begin{array}{l l}
    \frac{x^\lambda - 1}{\lambda} &amp; \quad \text{if $\lambda \neq 0$}\\
    \log(x) &amp; \quad \text{if $\lambda=0$}
  \end{array} \right.
\]</span></p>
<p>To calculate skewness:</p>
<pre class="r"><code>library(e1071)
skewness(segData$AngleCh1)</code></pre>
<pre><code>## [1] -0.02426</code></pre>
<pre class="r"><code>head(sapply(segData, skewness))</code></pre>
<pre><code>##    AngleCh1     AreaCh1 AvgIntenCh1 AvgIntenCh2 AvgIntenCh3 AvgIntenCh4 
##    -0.02426     3.52511     2.95919     0.84816     2.20234     1.90047</code></pre>
<p>Box-Cox transformation:</p>
<pre class="r"><code>hist(segData$PerimCh1, breaks=30, main=&quot;Before BoxCox Transformation&quot;)

library(caret)</code></pre>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2</code></pre>
<p><img src="CH03_files/figure-html/unnamed-chunk-21.png" title="plot of chunk unnamed-chunk-2" alt="plot of chunk unnamed-chunk-2" width="672" /></p>
<pre class="r"><code>periTrans = BoxCoxTrans(segData$PerimCh1)
periTrans</code></pre>
<pre><code>## Box-Cox Transformation
## 
## 1009 data points used to estimate Lambda
## 
## Input data summary:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    47.7    64.4    79.0    91.6   103.0   460.0 
## 
## Largest/Smallest: 9.63 
## Sample Skewness: 2.59 
## 
## Estimated Lambda: -1.1</code></pre>
<pre class="r"><code>nsk = predict(periTrans, segData$PerimCh1)
hist(nsk, breaks=30, main=&quot;After BoxCox Transformation&quot;)</code></pre>
<p><img src="CH03_files/figure-html/unnamed-chunk-22.png" title="plot of chunk unnamed-chunk-2" alt="plot of chunk unnamed-chunk-2" width="672" /></p>
</div>
</div>
<div id="data-transormations-for-multiple-predictors" class="section level1">
<h1><span class="header-section-number">2</span> Data Transormations for Multiple Predictors</h1>
<div id="transformations-to-resolve-outliers" class="section level2">
<h2><span class="header-section-number">2.1</span> Transformations to Resolve Outliers</h2>
<p>When outliers are present, first make sure that the values are scientiffically valid and that no data recording errors have occurred. Great care should be taken not to hastily remove or change values, especially if the sample size is small. With small sample sizes, apparent outliers might be result of a skewed distribution where there are not yet enough data to see the skewness.</p>
<p>Tree-based classifications suppport vector machines for classification generally are resistant to outliers.</p>
<p><strong>Spatial sign</strong> transformation is designed to resolve outliers: <span class="math">\[ x_{ij}^* = \frac{x_{ij}}{\sum^P_{j=1} x^2_{ij}} \]</span></p>
<pre class="r"><code>set.seed(123)
x = rnorm(1000)
y = 10 * x + rnorm(1000)
y[1:3] = 5 * y[1:3] 
d = data.frame(x=x, y=y)
plot(d, main=&quot;With Outliers&quot;)
points(x=d[1:3, &quot;x&quot;], y=d[1:3, &quot;y&quot;], col=&quot;red&quot;, pch=16)</code></pre>
<p><img src="CH03_files/figure-html/unnamed-chunk-31.png" title="plot of chunk unnamed-chunk-3" alt="plot of chunk unnamed-chunk-3" width="672" /></p>
<pre class="r"><code>dTrans = preProcess(d, method=c(&quot;spatialSign&quot;))
newd = predict(dTrans, d)
plot(newd)
points(x=newd[1:3, &quot;x&quot;], y=newd[1:3, &quot;y&quot;], col=&quot;red&quot;, pch=16)</code></pre>
<p><img src="CH03_files/figure-html/unnamed-chunk-32.png" title="plot of chunk unnamed-chunk-3" alt="plot of chunk unnamed-chunk-3" width="672" /></p>
</div>
<div id="data-reduction-and-feature-extraction" class="section level2">
<h2><span class="header-section-number">2.2</span> Data Reduction and Feature Extraction</h2>
<p>The main method of dim reduction is PCA, but it is a <em>unsupervised</em> transformation.</p>
<pre class="r"><code>trans = preProcess(segData, 
                   method=c(&quot;BoxCox&quot;, &quot;center&quot;, &quot;scale&quot;, &quot;pca&quot;))
trans</code></pre>
<pre><code>## 
## Call:
## preProcess.default(x = segData, method = c(&quot;BoxCox&quot;, &quot;center&quot;,
##  &quot;scale&quot;, &quot;pca&quot;))
## 
## Created from 1009 samples and 58 variables
## Pre-processing: Box-Cox transformation, centered, scaled,
##  principal component signal extraction 
## 
## Lambda estimates for Box-Cox transformation:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##  -2.000  -0.500  -0.100   0.051   0.300   2.000      11 
## 
## PCA needed 19 components to capture 95 percent of the variance</code></pre>
<pre class="r"><code>segNew = predict(trans, segData)
head(segNew[, 1:5])</code></pre>
<pre><code>##        PC1     PC2     PC3    PC4     PC5
## 2   1.5685  6.2908 -0.3333 -3.063 -1.3416
## 3  -0.6664  2.0455 -1.4417 -4.701 -1.7422
## 4   3.7500 -0.3916 -0.6690 -4.021  1.7928
## 12  0.3769 -2.1898  1.4380 -5.327 -0.4067
## 15  1.0645 -1.4647 -0.9900 -5.627 -0.8650
## 16 -0.3799  0.2173  0.4388 -2.070 -1.9364</code></pre>
</div>
</div>
<div id="dealing-with-missing-values" class="section level1">
<h1><span class="header-section-number">3</span> Dealing with Missing Values</h1>
<p>First modeler should be ware about why values are missing, as missing itself can be a kind of message. Several methods can be used to impute missing values, as shown below.</p>
<pre class="r"><code>d[21:25, &quot;y&quot;] &lt;- NA
d[20:27, ]</code></pre>
<pre><code>##          x       y
## 20 -0.4728  -2.979
## 21 -1.0678      NA
## 22 -0.2180      NA
## 23 -1.0260      NA
## 24 -0.7289      NA
## 25 -0.6250      NA
## 26 -1.6867 -16.638
## 27  0.8378  10.031</code></pre>
<pre class="r"><code>trans = preProcess(d, method=c(&quot;center&quot;, &quot;scale&quot;, &quot;medianImpute&quot;))
newd = predict(trans, d)
newd[20:27,]</code></pre>
<pre><code>##          x       y
## 20 -0.4930 -0.3114
## 21 -1.0930  0.2061
## 22 -0.2361  0.2061
## 23 -1.0509  0.2061
## 24 -0.7513  0.2061
## 25 -0.6465  0.2061
## 26 -1.7171 -1.6231
## 27  0.8285  0.9379</code></pre>
<pre class="r"><code>plot(newd)
points(newd[21:25,], pch=16, col=&quot;red&quot;)</code></pre>
<p><img src="CH03_files/figure-html/unnamed-chunk-51.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="672" /></p>
<pre class="r"><code>trans = preProcess(d, method=c(&quot;center&quot;, &quot;scale&quot;, &quot;knnImpute&quot;))
newd = predict(trans, d)
newd[20:27,]</code></pre>
<pre><code>##          x       y
## 20 -0.4930 -0.3114
## 21 -1.0930 -1.0048
## 22 -0.2361 -0.2659
## 23 -1.0509 -0.9914
## 24 -0.7513 -0.7419
## 25 -0.6465 -0.6641
## 26 -1.7171 -1.6231
## 27  0.8285  0.9379</code></pre>
<pre class="r"><code>plot(newd)
points(newd[21:25,], pch=16, col=&quot;red&quot;)</code></pre>
<p><img src="CH03_files/figure-html/unnamed-chunk-52.png" title="plot of chunk unnamed-chunk-5" alt="plot of chunk unnamed-chunk-5" width="672" /></p>
</div>
<div id="removing-predictors" class="section level1">
<h1><span class="header-section-number">4</span> Removing Predictors</h1>
<div id="zero-variance-predictors" class="section level2">
<h2><span class="header-section-number">4.1</span> Zero Variance Predictors</h2>
<p>Zero or near zero variance predictors carry very limited infomation, while they can dramatically affect some linear models performance, thus one should consider removing them.</p>
<pre class="r"><code>nearZeroVar(segData)</code></pre>
<pre><code>## integer(0)</code></pre>
<pre class="r"><code>segData$test = 1
nzs = nearZeroVar(segData)
segData = subset(segData, select=-nzs)</code></pre>
</div>
<div id="betwee-predictor-correlations" class="section level2">
<h2><span class="header-section-number">4.2</span> Betwee-Predictor Correlations</h2>
<p>Many linear models are exposed to colinear problems. Except for dimension reduction methods, one can also consider about removing high correlated predictors.</p>
<pre class="r"><code>corrs = cor(segData)
dim(corrs)</code></pre>
<pre><code>## [1] 58 58</code></pre>
<pre class="r"><code>library(corrplot)
corrplot(corrs)</code></pre>
<p><img src="CH03_files/figure-html/unnamed-chunk-7.png" title="plot of chunk unnamed-chunk-7" alt="plot of chunk unnamed-chunk-7" width="672" /></p>
<pre class="r"><code>highCorr = findCorrelation(corrs, cutoff=.75)
head(highCorr)</code></pre>
<pre><code>## [1] 23 40 43 36  7 15</code></pre>
<pre class="r"><code>length(highCorr)</code></pre>
<pre><code>## [1] 33</code></pre>
<pre class="r"><code>filtered = segData[, -highCorr]</code></pre>
</div>
</div>
<div id="adding-predictors" class="section level1">
<h1><span class="header-section-number">5</span> Adding Predictors</h1>
<p>It’s common to encode category predictors to set of dummy variables.</p>
<pre class="r"><code># Let me make a categorical var first...
data(cars, package=&quot;caret&quot;)
names(cars)</code></pre>
<pre><code>##  [1] &quot;Price&quot;       &quot;Mileage&quot;     &quot;Cylinder&quot;    &quot;Doors&quot;       &quot;Cruise&quot;     
##  [6] &quot;Sound&quot;       &quot;Leather&quot;     &quot;Buick&quot;       &quot;Cadillac&quot;    &quot;Chevy&quot;      
## [11] &quot;Pontiac&quot;     &quot;Saab&quot;        &quot;Saturn&quot;      &quot;convertible&quot; &quot;coupe&quot;      
## [16] &quot;hatchback&quot;   &quot;sedan&quot;       &quot;wagon&quot;</code></pre>
<pre class="r"><code>subCars = subset(cars, select=c(Price, Mileage, convertible:wagon))
categoryNames = names(subset(cars, select=convertible:wagon))
type = as.matrix(subset(subCars, select=convertible:wagon)) %*% 1:5
subCars$Type = factor(type, labels=categoryNames)
subCars = subset(subCars, select=c(Price, Mileage, Type))
head(subCars)</code></pre>
<pre><code>##   Price Mileage        Type
## 1 22661   20105       sedan
## 2 21725   13457       coupe
## 3 29143   31655 convertible
## 4 30732   22479 convertible
## 5 33359   17590 convertible
## 6 30315   23635 convertible</code></pre>
<pre class="r"><code>dummyTrans = dummyVars(~Price+Mileage+Type+Mileage:Type, data=subCars, levelsOnly=T)
dummySubCars = predict(dummyTrans, subCars)
head(dummySubCars)</code></pre>
<pre><code>##   Price Mileage convertible coupe hatchback sedan wagon
## 1 22661   20105           0     0         0     1     0
## 2 21725   13457           0     1         0     0     0
## 3 29143   31655           1     0         0     0     0
## 4 30732   22479           1     0         0     0     0
## 5 33359   17590           1     0         0     0     0
## 6 30315   23635           1     0         0     0     0
##   Mileage:convertible Mileage:coupe Mileage:hatchback Mileage:sedan
## 1                   0             0                 0         20105
## 2                   0         13457                 0             0
## 3               31655             0                 0             0
## 4               22479             0                 0             0
## 5               17590             0                 0             0
## 6               23635             0                 0             0
##   Mileage:wagon
## 1             0
## 2             0
## 3             0
## 4             0
## 5             0
## 6             0</code></pre>
</div>
<div id="binning-predictors" class="section level1">
<h1><span class="header-section-number">6</span> Binning Predictors</h1>
<p>This transformation should be AVOIDED.</p>
</div>

<section class="comment">
<div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rnotes'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with --self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
